"""
File   : chat_agent.py
Desc   : MCP ReAct æ™ºèƒ½ä½“
Date   : 2025/12/23
Author : Tianyu Chen
"""

import sys
import json
import time
import shlex
from pathlib import Path
import chainlit as cl
from openai import AsyncOpenAI
from loguru import logger

# å¼•å…¥åŸºç¡€è®¾æ–½å±‚
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from src.utils.mcp_client import mcp_client_instance

# åˆå§‹åŒ– Client
client = AsyncOpenAI()

async def react(message: cl.Message):
    """
    ReAct æ™ºèƒ½ä½“å…¥å£
    """
    logger.info("\n\n\n==================[System] New message received. Processing...==================")
    logger.info(f"\n[User] {message.content}")
    user_input = message.content.strip()

    # === å¸®åŠ©å‘½ä»¤å¤„ç† ===
    help_content="""
**Available Commands!**

- Use `@folders` to see available topics
- Use `@<topic>` to search papers in that topic
- Use `/prompts` to list available prompts
- Use `/prompt <name> <arg1=value1>` to execute a prompt"
"""
    if user_input.startswith("@help"):
        await cl.Message(content=help_content).send()
        return
    
    # === A. èµ„æºæŸ¥çœ‹ (@resource) ===
    if user_input.startswith("@"):
        uri_suffix = user_input[1:].strip()
        uri = "papers://folders" if uri_suffix == "folders" else f"papers://{uri_suffix}"
        
        async with cl.Step(name="Fetch Resource") as step:
            step.input = uri
            try:
                content = await mcp_client_instance.read_resource(uri)
                step.output = content[:500] + "..." if len(content) > 500 else content
            except Exception as e:
                step.output = f"Error: {str(e)}"
        
        await cl.Message(content=f"ğŸ“„ **Resource Content**:\n\n{content}\n").send()
        return

    # === B. åˆ—å‡º Prompts (/prompts) ===
    if user_input == "/prompts":
        prompts = mcp_client_instance.get_available_prompts()
        out_lines = ["ğŸ“‹ **Available Prompts**:"]
        for prompt in prompts:
            out_lines.append(f"- **{prompt['name']}**: {prompt['description']}")
            if prompt['arguments']:
                out_lines.append("  - Arguments:")
                for arg in prompt['arguments']:
                    arg_name = arg.name if hasattr(arg, 'name') else arg.get('name', '')
                    out_lines.append(f"    - {arg_name}")
        await cl.Message(content="\n".join(out_lines)).send()
        return

    # === C. æ‰§è¡Œ Prompt (/prompt) ===
    if user_input.startswith("/prompt"):
        # try-except ç”¨äºæ•è·å¼•å·ä¸åŒ¹é…çš„æƒ…å†µï¼ˆæ¯”å¦‚åªå†™äº†ä¸€ä¸ª "ï¼‰
        try:
            # ä½¿ç”¨ shlex.split æ¥è§£æå‚æ•°
            parts = shlex.split(user_input)
        except ValueError as e:
            await cl.Message(content=f"âš ï¸ å‚æ•°è§£æé”™è¯¯: å¼•å·æœªé—­åˆ ({e})").send()
            return

        if len(parts) < 2:
            await cl.Message(content="ç”¨æ³•: `/prompt <name> <arg1=value1> ...`").send()
            return

        prompt_name = parts[1]
        args = {}

        # <--- 3. éå†è§£æåçš„éƒ¨åˆ†
        for arg in parts[2:]:
            if '=' in arg:
                k, v = arg.split('=', 1)
                args[k] = v
            else:
                # å¯é€‰ï¼šå¤„ç†æ²¡æœ‰ç­‰å·çš„æƒ…å†µï¼Œæˆ–è€…ç›´æ¥å¿½ç•¥
                pass

        async with cl.Step(name="Execute Prompt") as step:
            step.input = f"Prompt: {prompt_name}, Args: {args}"
            try:
                prompt_content = await mcp_client_instance.get_prompt(prompt_name, args)
                # å…¼å®¹å¤„ç†ï¼šæœ‰çš„ Prompt è¿”å›å¯¹è±¡ï¼Œæœ‰çš„è¿”å› list
                final_input = str(prompt_content.messages[0].content.text) if hasattr(prompt_content, 'messages') else str(prompt_content)
                step.output = final_input
            except Exception as e:
                step.output = f"Error: {e}"
                await cl.Message(content=f"âŒ Prompt Error: {e}").send()
                return

        user_input = final_input

    # 2. è¿›å…¥ ReAct å¾ªç¯é€»è¾‘
    await run_react_cycle(user_input)
    logger.info("\n==================[System] Message processing completed.]==================\n\n")

def get_system_prompt(model_settings):
    """
    è·å–ç³»ç»Ÿæç¤ºè¯
    """
    return f"""  
# Role
{model_settings['RoleSetting']}

# Background
- Current System Time: {time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())}

# Workflow
- You will alternate between thinking, acting (using tools available), observing (tool results), and answering.
- If no tools are needed, provide a direct answer in clear and concise Markdown format.

# Constraints
- Do speak in Chinese.
- **Use standard Markdown formatting.**
- When using tools, ensure your tool calls are well-formed.
    """

async def run_react_cycle(user_query: str):
    """
    ReAct æ ¸å¿ƒå¾ªç¯ (Text -> Tool -> Text)
    """
    # è·å–ä¸Šä¸‹æ–‡
    message_history = cl.user_session.get("message_history", [])
    model_settings = cl.user_session.get("model_settings")
    
    # æ„é€  System Prompt
    system_prompt = get_system_prompt(model_settings)
    if not message_history or message_history[0]["role"] != "system":
        message_history.insert(0, {"role": "system", "content": system_prompt})
    else:
        message_history[0]["content"] = system_prompt
    
    message_history.append({"role": "user", "content": user_query})
    
    # æ‡’åŠ è½½æ¶ˆæ¯å¯¹è±¡ï¼ˆä¸ç«‹å³å‘é€ï¼‰
    current_message = cl.Message(content="")

    MAX_ROUNDS = 10
    current_round = 0
    
    while current_round < MAX_ROUNDS:
        current_round += 1
        message_sent = False
        tools = mcp_client_instance.get_tools_definitions()
        
        # --- 1. è°ƒç”¨æ¨¡å‹ ---
        try:
            stream = await client.chat.completions.create(
                model=model_settings["Model"],
                messages=message_history,
                tools=tools if tools else None,
                tool_choice="auto" if tools else None,
                stream=True,
                temperature=model_settings["Temperature"],
                extra_body={"enable_thinking": model_settings["Thinking"]} 
            )
        except Exception as e:
            err_msg = f"âš ï¸ Model API Error: {str(e)}"
            logger.error(err_msg)
            if not message_sent:
                await current_message.send()
            current_message.content += f"\n{err_msg}"
            await current_message.update()
            break

        # [State] æœ¬è½®æ•°æ®ç¼“å­˜
        current_thought = ""
        current_answer = ""
        tool_calls_buffer = {}
        
        # --- 2. å¤„ç†æµå¼å“åº” ---
        async for chunk in stream:
            delta = chunk.choices[0].delta
            
            # A. æ”¶é›†æ€è€ƒ (Reasoning)
            reasoning = getattr(delta, "reasoning_content", None)
            if reasoning and model_settings["Thinking"]:
                current_thought += reasoning
            
            # B. æ”¶é›†æ­£æ–‡ (Content)
            if delta.content:
                current_answer += delta.content
            
            # C. æ”¶é›†å·¥å…·è°ƒç”¨ (Tool Calls)
            if delta.tool_calls:
                for tool_call in delta.tool_calls:
                    idx = tool_call.index
                    if idx not in tool_calls_buffer:
                        tool_calls_buffer[idx] = {
                            "id": tool_call.id,
                            "name": tool_call.function.name or "",
                            "args": tool_call.function.arguments or ""
                        }
                    else:
                        if tool_call.function.name:
                            tool_calls_buffer[idx]["name"] = tool_call.function.name
                        if tool_call.function.arguments:
                            tool_calls_buffer[idx]["args"] += tool_call.function.arguments

            # === æ¸²æŸ“é€»è¾‘ï¼šMarkdown å¼•ç”¨å—æ ¼å¼ ===
            # æ ¼å¼ï¼š > æ€è€ƒå†…å®¹ \n\n æ­£æ–‡å†…å®¹

            display_parts = []

            if current_thought:
                # ç®€å•å¤„ç†ï¼šç»™æ¯ä¸€è¡ŒåŠ  >ï¼Œæˆ–è€…ç›´æ¥å…¨å—åŠ  >
                # ä¸ºäº†æµå¼æ•ˆæœå¥½ï¼Œé€šå¸¸ç›´æ¥å‰é¢åŠ  >ï¼Œæ¢è¡Œç¬¦æ›¿æ¢ä¸º \n>
                formatted_thought = "> " + current_thought.replace("\n", "\n> ")
                display_parts.append(formatted_thought)
            
            if current_answer:
                display_parts.append(current_answer)
            
            full_content = "\n\n".join(display_parts)
            
            if full_content:
                current_message.content = full_content
                if not message_sent:
                    await current_message.send()
                    message_sent = True
                else:
                    await current_message.update()

        # æµç»“æŸåçš„æœ€ç»ˆçŠ¶æ€è®°å½•
        full_content = current_message.content
        assistant_msg = {"role": "assistant", "content": current_answer} # å†å²è®°å½•é‡Œåªå­˜æ­£æ–‡ï¼Œä¸å­˜æ€è€ƒè¿‡ç¨‹(å¯é€‰)
        if current_thought:
            logger.debug(f"\n[ğŸ§  Thinking] {current_thought}")
        if current_answer:
            logger.debug(f"\n[ğŸ§¸ Answer] {current_answer}")

        # --- 3. å·¥å…·è°ƒç”¨ä¸å¾ªç¯æ§åˆ¶ ---
        if tool_calls_buffer:
            # æ•´ç†å·¥å…·è°ƒç”¨å‚æ•°
            proper_tool_calls = []
            for idx, data in tool_calls_buffer.items():
                proper_tool_calls.append({
                    "id": data["id"],
                    "type": "function",
                    "function": {"name": data["name"], "arguments": data["args"]}
                })

            # è®°å½• Assistant æ¶ˆæ¯ï¼ˆå¸¦ ToolCallï¼‰
            assistant_msg["tool_calls"] = proper_tool_calls
            message_history.append(assistant_msg) 

            # æ‰§è¡Œå·¥å…·
            for tool in proper_tool_calls:
                func_name = tool["function"]["name"]
                call_id = tool["id"]
                args_str = tool["function"]["arguments"]
 
                async with cl.Step(name=func_name, type="tool") as step:
                    step.input = args_str
                    try:
                        args = json.loads(args_str)
                        tool_result = await mcp_client_instance.call_tool(func_name, args)
                        # ç¡®ä¿ç»“æœæ˜¯å­—ç¬¦ä¸²
                        if not isinstance(tool_result, str):
                            tool_result = json.dumps(tool_result, ensure_ascii=False)
                        step.output = tool_result
                    except Exception as e:
                        tool_result = f"Error: {str(e)}"
                        step.output = tool_result
                        step.is_failed = True

                    message_history.append({
                        "role": "tool",
                        "tool_call_id": call_id,
                        "name": func_name,
                        "content": tool_result
                    })

            # å‡†å¤‡ä¸‹ä¸€è½®ï¼šåˆ›å»ºæ–°çš„æ¶ˆæ¯å¯¹è±¡ï¼Œä½†ä¸ç«‹å³å‘é€
            current_message = cl.Message(content="")

        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå¯¹è¯ç»“æŸ
            message_history.append(assistant_msg)
            break
