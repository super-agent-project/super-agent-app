# ğŸ§¸ Super Agent

**Slogan**: æ‰“é€ ä½ çš„è¶…çº§ AI åŠ©æ‰‹ï¼(Build your super AI assistant!)

## ğŸ› ï¸ å‡†å¤‡ç¯å¢ƒ

### æŠ€æœ¯é€‰å‹

* ç¼–ç¨‹è¯­è¨€ï¼š[Python 3](https://docs.python.org/3/)
* é¡¹ç›®ç¯å¢ƒå’Œä¾èµ–ç®¡ç†ï¼š[uv](https://uv.doczh.com/)
* æ—¥å¿—æ¡†æ¶ï¼š[loguru](https://loguru.readthedocs.io/en/stable/overview.html)
* å•å…ƒæµ‹è¯•ï¼š[pytest](https://docs.pytest.org/en/stable/)
* é¡¹ç›®éƒ¨ç½²ï¼š[docker](https://docs.docker.com/get-started/)
* æ¨¡å‹è°ƒç”¨ï¼š[OpenAI Python SDK](https://bailian.console.aliyun.com/?spm=a2ty02.30268951.d_model-market.2.67f074a1VkwhFN&tab=api#/api/?type=model&url=2712576)
* AI åº”ç”¨ UI æ¡†æ¶ï¼š[chainlit](https://docs.chainlit.io/get-started/overview)
* å…¶ä»–ä¾èµ–éšåŠŸèƒ½è¿­ä»£ç»§ç»­è¡¥å……...

### åˆ›å»ºå·¥ç¨‹

```shell
mkdir super-agent-project && cd super-agent-project
mkdir super-agent-app && cd super-agent-app
```

### å®‰è£…ä¾èµ–

```shell
# åˆå§‹åŒ–é¡¹ç›®
uv init
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆ.venvï¼‰å¹¶æ·»åŠ ä¾èµ–
uv add loguru pytest pytest-mock openai chainlit
```

**æ³¨æ„â—ï¸**ï¼šä»¥ä¸Šä¸ºä½œè€…åˆæ¬¡å®‰è£…ä¾èµ–ï¼Œå…¶ä»–å¼€å‘è€… clone é¡¹ç›®åï¼Œç›´æ¥åœ¨é¡¹ç›®è·¯å¾„ä¸‹è¿è¡Œ `uv sync` å³å¯ã€‚

### æ—¥å¿—ç­–ç•¥

* æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼šlogs/app.log
* æ—¥å¿—è½®è½¬ç­–ç•¥ï¼šæ¯å‘¨ä¸€åˆå¤œè½®è½¬
* æ—¥å¿—ä¿ç•™ç­–ç•¥ï¼š6 ä¸ªæœˆ

è¯¦è§ï¼š[src/utils/loguru_utils.py](src/utils/loguru_utils.py)

### åˆå§‹åŒ– Chainlit

```shell
chainlit init
```

**æ³¨æ„â—ï¸**ï¼šä½œè€…å·²ç»æ‰§è¡Œï¼Œå…¶ä»–å¼€å‘è€…æ— éœ€å†æ¬¡æ‰§è¡Œã€‚

### ç¯å¢ƒå˜é‡

* ä½œè€…é‡‡ç”¨[é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°](https://bailian.console.aliyun.com/?spm=5176.28197581.0.0.12dd29a4fpkfTO&tab=doc#/doc)æä¾›çš„ LLM æ¨¡å‹æœåŠ¡ã€‚
* æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å‰è¯·å°† `sk-xxx` æ›¿æ¢ä¸ºè‡ªå·±çš„ `API Key`ã€‚

```shell
cat > .env << 'EOF'
# æ¨¡å‹é…ç½®
OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
OPENAI_API_KEY=sk-xxx
EOF
```

**é‡è¦â€¼ï¸**ï¼šä¸€å®šè®°å¾—åœ¨ `.gitignore` æ–‡ä»¶ä¸­æ·»åŠ  `.env`ï¼Œä»¥å…å°†å…¶æäº¤åˆ°ä»“åº“ä»è€Œå¯¼è‡´ `API Key` æ³„éœ²ã€‚

### å¯åŠ¨é¡¹ç›®

```shell
# åˆ›å»ºæ–°ç»ˆç«¯ï¼Œè¿›å…¥é¡¹ç›®è·¯å¾„
cd super-agent-app

# å¯åŠ¨é¡¹ç›®ï¼ˆå¼€å‘æ¨¡å¼åŠ ä¸Š -w å¯è‡ªåŠ¨æ£€æµ‹ä»£ç æ›´æ–°ï¼‰
uv run chainlit run app.py
```

## ğŸ’¬ èŠå¤©å¯¹è¯ï¼šv0.1.0

å®ç°åŸºç¡€çš„èŠå¤©å¯¹è¯åŠŸèƒ½ï¼Œæ”¯æŒæµå¼å“åº”ã€æ€è€ƒæ¨¡å¼ã€‚

### ç›¸å…³ä»£ç 

```text
app.py  # ä»£ç å…¥å£
  - start_chat()   # å½“ç”¨æˆ·é¦–æ¬¡æ‰“å¼€èŠå¤©æ—¶è§¦å‘ï¼Œè·å–å¹¶å­˜å‚¨æ¨¡å‹è®¾ç½®
  - setup_agent()  # å½“ç”¨æˆ·æ›´æ–°è®¾ç½®æ—¶è§¦å‘ï¼Œæ›´æ–°èŠå¤©æ¨¡å‹è®¾ç½®
  - main()         # å½“ç”¨æˆ·å‘é€æ¶ˆæ¯æ—¶è§¦å‘ï¼Œå¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶ç”Ÿæˆå“åº”

src  # æ ¸å¿ƒæºç 
  - agent
      - chat_agent   # èŠå¤©æ™ºèƒ½ä½“ï¼Œæ”¯æŒæµå¼å’Œé˜»å¡å¼å“åº”ï¼Œæ”¯æŒæ€è€ƒæ¨¡å¼
  - ui
      - thinking_ui  # ä¸ªæ€§åŒ–æ€è€ƒè¿‡ç¨‹ UI ç»„ä»¶
  - utils
      - loguru_utils              # loguru æ—¥å¿—å·¥å…·
          - config_loguru()           # åˆå§‹åŒ–æ—¥å¿—é…ç½®
      - chainlit_utils            # chainlit å·¥å…·
          - get_model_settings()      # è·å–èŠå¤©æ¨¡å‹è®¾ç½®ï¼Œå¦‚æ¨¡å‹ã€æµå¼è¾“å‡ºã€æ·±åº¦æ€è€ƒã€è§’è‰²è®¾å®šç­‰

public  # ä¸ªæ€§åŒ–è®¾ç½®
  - favicon.png     # ä¸ªæ€§åŒ–ç½‘é¡µå›¾æ ‡
  - logo_light.png  # æµ…è‰²ä¸»é¢˜ä¸‹çš„ä¸ªæ€§åŒ–ç½‘ç«™ logo
  - logo_dark.png   # æ·±è‰²ä¸»é¢˜ä¸‹çš„ä¸ªæ€§åŒ–ç½‘ç«™ logo
  - theme.json      # ä¸»é¢˜è®¾ç½®
      - "--primary": "221.2 83.2% 53.3%"  # ä¸»è‰²è°ƒæ”¹ä¸ºè“è‰²ï¼ˆæµ…è‰²å’Œæ·±è‰²ä¸»é¢˜éƒ½è¦æ”¹ï¼‰
      - "--ring": "221.2 83.2% 53.3%"     # èšç„¦ç¯æ”¹ä¸ºè“è‰²ï¼ˆæµ…è‰²å’Œæ·±è‰²ä¸»é¢˜éƒ½è¦æ”¹ï¼‰

.chainlit  # chainlit é…ç½®
  - config.toml     # chainlit é…ç½®æ–‡ä»¶
      - [UI]            # UI ç›¸å…³é…ç½®
          - name = "SuperAgent"               # è®¾ç½®ç½‘ç«™åç§°
          - default_theme = "light"           # é»˜è®¤ä¸ºæµ…è‰²ä¸»é¢˜
          - description = "ä½ çš„è¶…çº§ AI åŠ©æ‰‹ã€‚"   # ç½‘ç«™æè¿°
          - language = "zh-CN"                # é»˜è®¤è¯­è¨€ä¸ºä¸­æ–‡
      - [features]      # åŠŸèƒ½é…ç½®
          - unsafe_allow_html = true          # æ¶ˆæ¯ä¸­å¯ç”¨ HTML æ˜¾ç¤ºï¼ˆä»¥å…è®¸ä¸ªæ€§åŒ–æ€è€ƒè¿‡ç¨‹ UI æ ·å¼ï¼‰
  - translations
      - zh-CN.json  # ä¸­æ–‡ç›¸å…³é…ç½®
          - watermark   # ä¿®æ”¹è„šæ³¨ä¸ºâ€œå†…å®¹ç”± AI ç”Ÿæˆï¼Œè¯·ä»”ç»†ç”„åˆ«â€
```

### å¯¹è¯å±•ç¤º

![ä¸»é¡µé¢](./images/01_ä¸»é¡µé¢.png)

![è®¾ç½®é¢æ¿](./images/02_è®¾ç½®é¢æ¿.png)

![å¯¹è¯](./images/03_å¯¹è¯.png)

## ğŸ¤– ReAct æ™ºèƒ½ä½“ï¼šv0.2.0

å®ç° ReAct æ™ºèƒ½ä½“ï¼Œé€šè¿‡ MCPï¼ˆstdio é€šä¿¡ï¼‰è¿›è¡Œå·¥å…·è°ƒç”¨ã€‚

### ç›¸å…³æŠ€æœ¯

* **ReAct: Synergizing reasoning and acting in language models** [[arXiv:2210.03629](https://arxiv.org/abs/2210.03629)]
  * 2022 å¹´ 10 æœˆç”±æ™®æ—æ–¯é¡¿å¤§å­¦å’Œè°·æ­Œç ”ç©¶é™¢è”åˆæå‡ºçš„ä¸€ç§èåˆ LLM æ¨ç†å’Œè¡ŒåŠ¨çš„æ–¹æ³•ï¼Œä»»åŠ¡çš„è§£å†³è½¨è¿¹åŒ…å«å¤šä¸ªâ€œæ€ç»´-åŠ¨ä½œ-è§‚å¯Ÿâ€æ­¥éª¤ã€‚
* **æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆ[Model Context Protocolï¼ŒMCP](https://modelcontextprotocol.io/docs/getting-started/intro)ï¼‰**
  * ç”±ç ”å‘ Claude æ¨¡å‹çš„ Anthropic å…¬å¸äº 2024 å¹´ 11 æœˆæå‡ºå¹¶å¼€æºã€‚è¯¥åè®®æ—¨åœ¨æ ‡å‡†åŒ– AI æ¨¡å‹ä¸å¤–éƒ¨æ•°æ®æºåŠå·¥å…·çš„äº¤äº’æ–¹å¼ï¼Œæ–¹ä¾¿ AI åº”ç”¨æ‹“å±•è‡ªèº«æˆ–é›†æˆæ’ä»¶ç”Ÿæ€ç³»ç»Ÿï¼Œåç»­è¿˜å¾—åˆ°äº† OpenAIã€è°·æ­Œã€é˜¿é‡Œäº‘ç­‰ä¼—å¤šä¼ä¸šçš„æ”¯æŒã€‚

### æ–°å¢ä»£ç 

```text
app.py   # ä»£ç å…¥å£
  - app_init()          # åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œä¸€æ¬¡ï¼Œåˆå§‹åŒ–å…¨å±€å•ä¾‹ MCP Client
  - app_shutdown()      # åº”ç”¨å…³é—­æ—¶æ‰§è¡Œä¸€æ¬¡ï¼Œæ¸…ç†èµ„æº
  - AGENT_MODE          # å…¨å±€å˜é‡ï¼Œå¯é€‰ Agent æ¨¡å¼ "CHAT" æˆ– "REACT"

configs  # é…ç½®æ•°æ®
  - server_config.json  # MCP Server é…ç½®
      - weather             # æŸ¥è¯¢å¤©æ°”æœåŠ¡ï¼ˆStreamable HTTPï¼‰
      - research            # å­¦æœ¯ç ”ç©¶æœåŠ¡ï¼ˆStreamable HTTPï¼‰
      - fetch               # å®˜æ–¹ MCP Serverï¼šURLå†…å®¹æå–ï¼ˆStdioï¼‰
      - filesystem          # å®˜æ–¹ MCP Serverï¼šæ–‡ä»¶ç³»ç»Ÿæ“ä½œï¼ˆStdioï¼‰ï¼Œæ³¨æ„éœ€è¦å®‰è£… Node.js ç¯å¢ƒï¼

src
  - utils
      - mcp_client   # å®šä¹‰å¹¶ç»´æŠ¤ä¸€ä¸ªå…¨å±€ MCP Client ç®¡ç†å™¨
          - MCPClientManager  # MCP Client ç®¡ç†å™¨ç±»
              - initialize()              # ä»é…ç½®æ–‡ä»¶è¯»å– MCP Server é…ç½®å¹¶å»ºç«‹è¿æ¥
              - _connect_to_server()      # è¿æ¥åˆ°å•ä¸ª MCP Server å¹¶å»ºç«‹ä¼šè¯ï¼Œæ”¯æŒ Stdio, SSE å’Œ Streamable HTTP é€šä¿¡åè®®
              - _register_capabilities()  # é€šè¿‡ä¼šè¯ä¸€æ¬¡æ€§æ³¨å†Œ Tools, Prompts, Resources
              - get_tools_definitions()   # è·å– OpenAI æ ¼å¼çš„å·¥å…·å®šä¹‰
              - call_tool()               # æ‰§è¡Œå·¥å…·
              - get_available_prompts()   # è·å–æ‰€æœ‰å¯ç”¨ Prompt åˆ—è¡¨
              - get_prompt()              # è·å– Prompt æ¨¡æ¿å†…å®¹
              - read_resource()           # è¯»å–èµ„æºå†…å®¹
      - chainlit_utils
          - react_model_settings          # ReAct æ™ºèƒ½ä½“æ¨¡å‹è®¾ç½®
  - agent
      - react_agent  # ReAct æ™ºèƒ½ä½“
```

### ReAct æ™ºèƒ½ä½“æµç¨‹å›¾

```mermaid
flowchart TD
    %% ================= æ ·å¼å®šä¹‰ =================
    classDef process fill:#e3f2fd,stroke:#1565c0,stroke-width:2px;
    classDef decision fill:#fff9c4,stroke:#fbc02d,stroke-width:2px;
    classDef external fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,stroke-dasharray: 5 5;
    classDef ui fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px;
    classDef terminal fill:#333,stroke:#333,stroke-width:2px,color:white,rx:10,ry:10;

    %% ================= ä¸»å…¥å£é€»è¾‘ =================
    Start([ç”¨æˆ·å‘é€æ¶ˆæ¯]) --> DetectCmd{"æ£€æŸ¥æŒ‡ä»¤å‰ç¼€"}

    %% --- 1. å¸®åŠ©æŒ‡ä»¤ ---
    DetectCmd -- "@help" --> ShowHelp[æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯] --> End([ç»“æŸ])

    %% --- 2. èµ„æºæŸ¥çœ‹ ---
    DetectCmd -- "@resource" --> ParseUri[è§£æ URI]
    ParseUri --> MCPRead["MCP: read_resource"]:::external
    MCPRead --> SendRes[å‘é€èµ„æºå†…å®¹] --> End

    %% --- 3. åˆ—å‡º Prompts ---
    DetectCmd -- "/prompts" --> MCPList["MCP: get_available_prompts"]:::external
    MCPList --> SendList[å‘é€ Prompt åˆ—è¡¨] --> End

    %% --- 4. æ‰§è¡Œ Prompt ---
    DetectCmd -- "/prompt" --> ParseArgs[è§£æå‚æ•°]
    ParseArgs --> MCPGet["MCP: get_prompt"]:::external
    MCPGet --> UpdateInput[æ›´æ–° user_input] --> InitReAct

    %% --- 5. æ™®é€šå¯¹è¯ (è¿›å…¥ ReAct) ---
    DetectCmd -- æ™®é€šæ–‡æœ¬ --> InitReAct

    %% ================= ReAct å¾ªç¯é€»è¾‘ =================
    subgraph ReAct_Cycle [run_react_cycle: æ™ºèƒ½ä½“å¾ªç¯]
        direction TB
        
        InitReAct[åˆå§‹åŒ–: å†å²è®°å½• & System Prompt] --> InitRound[Round = 0]
        InitRound --> CheckRound{"Round < MAX_ROUNDS?"}:::decision
        
        %% å¾ªç¯ç»“æŸæ¡ä»¶
        CheckRound -- No --> SaveHistEnd[ä¿å­˜å†å²] --> End
        
        %% å¾ªç¯å¼€å§‹
        CheckRound -- Yes --> StartRound[Round++]
        StartRound --> GetTools["MCP: get_tools"]:::external
        GetTools --> CallLLM["OpenAI API (Stream=True)"]:::external
        
        %% --- æµå¼å¤„ç†å­å›¾ ---
        subgraph Stream_Process [æµå¼å“åº”ä¸æ¸²æŸ“]
            direction TB
            ReceiveChunk[æ¥æ”¶ Chunk] --> AnalyzeChunk{"å†…å®¹ç±»å‹?"}:::decision
            
            AnalyzeChunk -- Reasoning --> CacheThink[ç´¯åŠ  current_thought]
            AnalyzeChunk -- Content --> CacheAns[ç´¯åŠ  current_answer]
            AnalyzeChunk -- ToolCall --> CacheTool[ç¼“å­˜ Tool å‚æ•°]
            
            CacheThink & CacheAns --> RenderMD["Markdown æ ¼å¼åŒ–:<br/>> æ€è€ƒ...<br/><br/>æ­£æ–‡..."]:::ui
            RenderMD --> CheckSent{"æ¶ˆæ¯å·²å‘é€?"}:::decision
            
            CheckSent -- No (æ‡’å‘é€) --> SendMsg[cl.Message.send]:::ui --> SetSent[æ ‡è®° sent=True]
            CheckSent -- Yes --> UpdateMsg[cl.Message.update]:::ui
            
            SetSent & UpdateMsg --> NextChunk[ç­‰å¾…ä¸‹ä¸€ Chunk]
            NextChunk -.-> ReceiveChunk
        end
        
        CallLLM --> Stream_Process
        Stream_Process -- æµç»“æŸ --> BuildMsg[æ„å»º Assistant Message]
        
        %% --- å†³ç­–åˆ†æ”¯ ---
        BuildMsg --> HasTools{"æœ‰å·¥å…·è°ƒç”¨?"}:::decision
        
        %% åˆ†æ”¯ A: æ‰§è¡Œå·¥å…·
        HasTools -- Yes (Action) --> RecordToolCall["è®°å½• Assistant(ToolCall) åˆ°å†å²"]
        RecordToolCall --> ExecToolLoop[éå†å·¥å…·åˆ—è¡¨]
        
        subgraph Tool_Execution [å·¥å…·æ‰§è¡Œ]
            ExecToolLoop --> CallMCPTool["MCP: call_tool"]:::external
            CallMCPTool --> ShowStep[æ˜¾ç¤º Chainlit Step]:::ui
            ShowStep --> RecordResult["è¿½åŠ  Tool Result åˆ°å†å²"]
        end
        
        RecordResult --> ResetMsg["é‡ç½® current_message<br/>(ä¸ç«‹å³å‘é€)"]
        ResetMsg --> CheckRound
        
        %% åˆ†æ”¯ B: ç»“æŸå¯¹è¯
        HasTools -- No (Answer) --> RecordAns["è®°å½• Assistant(Content) åˆ°å†å²"]
        RecordAns --> SaveHistEnd
    end

    %% ================= æ ·å¼åº”ç”¨ =================
    class Start,End terminal;
    class DetectCmd,CheckRound,AnalyzeChunk,CheckSent,HasTools decision;
    class ShowHelp,ParseUri,SendRes,SendList,ParseArgs,UpdateInput,InitReAct,InitRound,StartRound,CacheThink,CacheAns,CacheTool,BuildMsg,RecordToolCall,ExecToolLoop,RecordResult,ResetMsg,RecordAns,SaveHistEnd process;
    class MCPRead,MCPList,MCPGet,GetTools,CallLLM,CallMCPTool external;
    class RenderMD,SendMsg,UpdateMsg,ShowStep ui;
```

### æµ‹è¯•å¯¹è¯

**1. å¯åŠ¨ MCP æœåŠ¡**: [super-agent-mcp-server](https://github.com/super-agent-project/super-agent-mcp-server)

**2. å¯åŠ¨ ReAct æ™ºèƒ½ä½“**:

```shell
# new terminal
cd super-agent-app

uv run chainlit run app.py
```

![v020_01_start_app](./images/v020_01_start_app.png)

**3. æ‰“æ‹›å‘¼ (æ€è€ƒæ¨¡å¼)**:

![v020_02_hello](./images/v020_02_hello.png)

**3. å¤©æ°”æŸ¥è¯¢**:

![v020_03_weather](./images/v020_03_weather.png)

**4. ä½¿ç”¨æç¤ºè¯æ¨¡æ¿**:

![v020_04_prompt_help](./images/v020_04_prompt_help.png)
![v020_05_prompt_template](./images/v020_05_prompt_template.png)
![v020_06_prompt_result](./images/v020_06_prompt_result.png)

**5. æŸ¥çœ‹èµ„æº**:

![v020_07_resources_list](./images/v020_07_resources_list.png)
![v020_08_resource_detail](./images/v020_08_resource_detail.png)
